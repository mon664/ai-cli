use clap::{Parser, Subcommand};
use anyhow::Result;

mod cli;
mod git_utils;
mod ai_utils;
mod context;
mod security;
mod mcp;

use cli::*;
use git_utils::*;
use ai_utils::*;

#[tokio::main]
async fn main() -> Result<()> {
    // Î°úÍπÖ Ï¥àÍ∏∞Ìôî
    tracing_subscriber::fmt::init();

    let cli = Cli::parse();

    match &cli.command {
        Commands::Commit { message, all } => {
            println!("ü§ñ AI is generating your commit message...");

            // Î™®Îì† Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ Ïä§ÌÖåÏù¥Ïßï (ÏòµÏÖò)
            if *all {
                println!("üìã Staging all changes...");
                // TODO: git add -A Íµ¨ÌòÑ
            }

            // Ïä§ÌÖåÏù¥ÏßïÎêú diff ÏùΩÍ∏∞
            let diff = get_staged_diff()?;
            println!("üìù Analyzing {} lines of changes...", diff.lines().count());

            // Ïª§Î∞ã Î©îÏãúÏßÄ ÏÉùÏÑ±
            let commit_message = generate_commit_message(&diff).await?;

            // ÏÇ¨Ïö©Ïûê ÏäπÏù∏ Î∞è Ïª§Î∞ã Ïã§Ìñâ
            security::prompt_and_commit(&commit_message)?;
        }
        Commands::Explain { hash, model, detailed, format } => {
            println!("üîç AI is analyzing the changes...");

            // diff ÎòêÎäî ÌäπÏ†ï Ïª§Î∞ã Î∂ÑÏÑù
            let diff = if let Some(commit_hash) = hash {
                get_commit_diff(commit_hash)?
            } else {
                get_staged_diff()?
            };

            // AI Î∞±ÏóîÎìú ÏÑ†ÌÉù
            let backend = get_ai_backend(model)?;

            // Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ ÏÑ§Î™Ö ÏÉùÏÑ±
            let explanation = generate_explanation(&diff, *detailed, &backend).await?;

            match format.as_str() {
                "json" => {
                    let output = serde_json::json!({
                        "analysis": explanation,
                        "model": backend,
                        "detailed": detailed
                    });
                    println!("{}", serde_json::to_string_pretty(&output)?);
                }
                "markdown" => {
                    println!("## Code Change Analysis\n\n{}", explanation);
                }
                _ => {
                    println!("\nüìÑ AI Analysis:\n{}", explanation);
                }
            }
        }
        Commands::Init { model, openai_key, anthropic_key, ollama_url } => {
            println!("üîß Initializing AI CLI configuration...");

            // ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï ÏïàÎÇ¥
            if let Some(m) = model {
                println!("‚úì Default model set to: {}", m);
                std::env::set_var("AI_CLI_DEFAULT_MODEL", m);
            }

            if let Some(key) = openai_key {
                println!("‚úì OpenAI API key configured");
                std::env::set_var("OPENAI_API_KEY", key);
            }

            if let Some(key) = anthropic_key {
                println!("‚úì Anthropic API key configured");
                std::env::set_var("ANTHROPIC_API_KEY", key);
            }

            if ollama_url != "http://localhost:11434" {
                println!("‚úì Ollama URL set to: {}", ollama_url);
                std::env::set_var("AI_CLI_OLLAMA_URL", ollama_url);
            }

            // Í∏∞Î≥∏ ÏÑ§Ï†ï ÌååÏùº ÏÉùÏÑ±
            let current_dir = std::env::current_dir()?;
            if let Ok(config_path) = context::create_default_project_config(&current_dir) {
                println!("‚úì Created PROJECT.md at: {}", config_path.display());
            }

            if let Ok(config_path) = context::create_default_global_config() {
                println!("‚úì Created global config at: {}", config_path.display());
            }

            // MCP ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÌÖåÏä§Ìä∏
            let mcp_client = mcp::MCPClientBuilder::new("ai-cli")
                .version("0.1.0")
                .server_url("stdio://")
                .build();

            match mcp_client.initialize().await {
                Ok(()) => {
                    println!("‚úì MCP client initialized successfully");
                    let tools = mcp_client.list_tools();
                    if !tools.is_empty() {
                        println!("‚úì Available MCP tools: {}", tools.join(", "));
                    }
                }
                Err(e) => {
                    println!("‚ö† MCP client initialization failed: {}", e);
                    println!("  This is normal if no MCP server is installed.");
                }
            }

            println!("\nüéâ AI CLI initialization complete!");
            println!("Run 'ai-cli commit' to generate your first AI-powered commit message.");
        }
        Commands::Config { verbose } => {
            println!("‚öôÔ∏è  AI CLI Configuration");

            if *verbose {
                // ÌòÑÏû¨ ÏÑ§Ï†ï ÏÉÅÏÑ∏ Ï∂úÎ†•
                println!("\nEnvironment Variables:");
                if let Ok(model) = std::env::var("AI_CLI_LOCAL_MODEL") {
                    println!("  Local Model: {}", model);
                }
                if let Ok(url) = std::env::var("AI_CLI_OLLAMA_URL") {
                    println!("  Ollama URL: {}", url);
                }
                if let Ok(key) = std::env::var("OPENAI_API_KEY") {
                    println!("  OpenAI API: ‚úì configured");
                }
                if let Ok(key) = std::env::var("ANTHROPIC_API_KEY") {
                    println!("  Anthropic API: ‚úì configured");
                }

                // Ïª®ÌÖçÏä§Ìä∏ ÌååÏùº ÏÉÅÌÉú
                let current_dir = std::env::current_dir()?;
                let project_config = current_dir.join("PROJECT.md");
                if project_config.exists() {
                    println!("  Project Context: ‚úì {}", project_config.display());
                }

                let home_config = dirs::home_dir()
                    .map(|h| h.join(".ai-cli").join("CONFIG.md"));
                if let Some(ref config_path) = home_config {
                    if config_path.exists() {
                        println!("  Global Context: ‚úì {}", config_path.display());
                    }
                }
            } else {
                println!("Use --verbose for detailed configuration");
                println!("Run 'ai-cli init' to configure");
            }
        }
    }

    Ok(())
}